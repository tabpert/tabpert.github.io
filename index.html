<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8" />
    <title>TabPert</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#157879" />
    <link rel="stylesheet" href="css/normalize.css" />
    <link
      href="https://fonts.googleapis.com/css?family=Open+Sans:400,700"
      rel="stylesheet"
      type="text/css"
    />
    <link rel="stylesheet" href="css/cayman.css" />
  
  </head>
  <body>
    <section class="page-header">
<!--       <h1 style='font-size: 50px; color: #a12323'>TabPert</h1> -->
	   <h1><img src="figures/tabpert.png" style="max-width:40%;"></h1>
      <a onclick="switchTab(event, 'Home')"} class="btn tablinks">Home</a>
      <a href="https://aclanthology.org/2021.emnlp-demo.39.pdf" class="btn">Paper</a>
      <a href="https://github.com/utahnlp/tabpert/" class="btn">Code</a>
      <a onclick="switchTab(event, 'Instructions')" class="btn tablinks"
        >How To Use</a
      >
      <a href="https://www.youtube.com/watch?v=sbCH_zD53Kg" class="btn"
        >Demo</a
      >
      <a
        href="https://vgupta123.github.io/docs/tabpert_ppt.pdf"
        class="btn"
        >Slides</a
      ><br />
      <a href="https://youtube.com/watch?v=zjfRk8--jEY" class="btn"
        >Presentation</a
      >
	    <a href="https://infotabs.github.io" class="btn">InfoTabS</a>
	    			<a href="https://knowledge-infotabs.github.io" class="btn">Knowledge + InfoTabS</a>
			
    </section>
    <section id="Home" class="main-content tab" style="display: block">
      <h1>An Effective Platform for Tabular Perturbation</h1>

      <h2>
        <a
          id="user-content-header-2"
          class="anchor"
          href="#header-2"
          aria-hidden="true"
          ><span class="octicon octicon-link"></span></a
        >About
      </h2>
      <p style="text-align: justify">
        To truly grasp reasoning ability, a Natural Language Inference model
        should be evaluated on counterfactual data. TabPert facilitates this by
        assisting in the generation of such counterfactual data for assessing
        model tabular reasoning issues. TabPert allows a user to update a
        table, change its associated hypotheses, change their labels, and
        highlight rows that are important for hypothesis classification. TabPert
        also captures information about the techniques used to automatically
        produce the table, as well as the strategies employed to generate the
        challenging hypotheses. These counterfactual tables and hypotheses, as
        well as the metadata, can then be used to explore an existing model’s
        shortcomings methodically and quantitatively.
      </p>
      <p style="text-align: justify">
        <b>tl;dr</b>: TabPert is a tool to augment existing tabular datasets to
        effectively and efficiently create counterfactual datasets.
      </p>
      <p></p>
      
       <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Right Inference ≠ Right Reasoning </h2>
       <p>Existing NLI models tend to exploit annotation artefacts, pre-trained knowledge, and hypothesis biases in data to answer a premise. Therefore, to test their performance effectively, we must test them on <b>adversarial data</b>, on which their performance significantly reduces. However, perturbing existing tabular datasets to create counterfactual data is difficult and inefficient without specialised tools. This is where TabPert comes in!</p>
       
       <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Utility of TabPert</h2>
       <p>TabPert is built specifically to allow annotators to effectively and efficiently perturb tabular data and hypotheses. 
       <ul>
       	<li>TabPert <b>streamlines</b> the process of creating adversarial data</li>
       	<li  style="text-align: justify">TabPert logs data (called <b>metadata</b>) about the kinds of changes done to the dataset at each step of perturbation. This data can then be used to <b>analyse</b> models and <b>pinpoint their weaknesses</b></li>
       	<li>TabPert <b>automates</b> part of the perturbation process, making it easier for annotators to work while also reducing annotator bias</li>
       	<li>TabPert can be <b>customised</b> to any tabular perturbation task</li>
       </ul></p>
       
       <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example Table</h2>
			<p style="text-align: justify;">For a case study of TabPert, we use the <a href="https://infotabs.github.io">InfoTabS dataset</a>. Below is an inference example from InfoTabS. On the right is a premise and on the left are some of its hypotheses. Here, colors <span style='color:green;'>'green'</span>, <span style='color:darkgray;'>'gray'</span>, and <span style='color:red;'>'red'</span> represent true (i.e., entailment), maybe true (i.e., neutral) and false (i.e., contradiction) statements, respectively.</p>
			<p style="margin-left:10%; margin-right:10%;"><img src="figures/example.jpeg" style="max-width:95%;"></p>
       
       <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>How does it Work?</h2>
       <p>Annotation proceeds in two stages: the automatic stage followed by the manual stage. Metadata is collected in both stages: metadata for changes to the table is logged automatically, while metadata for hypothesis changes is input by the annotator.</p>
       <p>In the <b>automatic perturbation stage</b>, values are shuffled around the tables in the dataset. Values of one 'type' can be replaced by other values of the same type. These types must be specified beforehand. TabPert automatically logs the 'source' of each shuffled value, and this data  can be used to find shortcomings in the model like <b>overfitting</b>.</p>
       <p>In the <b>manual perturbation stage</b>, annotators correct any logical inconsistencies introduced in the table during the automatic stage, and perturb hypotheses. TabPert automatically logs the kinds of changes done to the table. For the hypotheses, the annotator must manually specify the <b>relevant rows</b> (sections in the table necessary to answer a hypothesis) as well as the <b>strategy</b> used to change each hypothesis. For more information about this stage, click <a onclick="switchTab(event, 'Instructions')" class="tablinks">here</a>.</p>
       
       
       <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h2>
       <p>Our team used TabPert to creat a counterfactual dataset from the InfoTabS dataset, consisting of 47 tables with 423 hypotheses. We sorted the hypotheses according to the perturbation strategy marked by the annotators and ran the InfoTabS RoBERTa<sub>Large</sub> model on them. The results are shown in the figures below. Note especially the significant performance drop on the counterfactual data in the first three strategies—these were the methods where annotators flipped the label of the hypothesis. So, collecting all that metadata has helped us detect significant hypothesis bias in the model!</p>
<p><img class="resp-img" src="figures/hypo_pert_stats1.jpg" /><img class="resp-img" src="figures/hypo_pert_stats2.jpg" /></p>
<p>Now, as another example, let's look at how the model performs when given only partial premises in the table below. First, note that when shown just the hypotheses without any premise, the model's performance is closer to majority-label baselines on the counterfactual dataset than on the original dataset. This confirms a reduction in hypothesis bias in the new dataset. Next, when shown only the relevant rows while answering a hypothesis, the model's performance falls on the original dataset, indicating that it utilises irrelevant rows as artefacts. However, in the same situation, the performance improves on the counterfactual dataset!</p>

<div>
<center>
				<table  style="margin-left:15%;
					margin-right:15%;
					caption-side:bottom;">
					<thead>
						<tr>
							<th>Model Type</th>
							<th>Original</th>
							<th>Counterfactual</th>
						</tr>
					</thead>
					<tbody align="center">
						<tr>
							<td>Majority</td>
							<td>33.33</td>
							<td>33.33</td>
						</tr>
						<tr>
							<td>Hypothesis Only</td>
							<td>64.32</td>
							<td>44.85</td>
						</tr>
						<tr>
							<td>All Rows</td>
							<td>78.91</td>
							<td>61.26</td>
						</tr>
						<tr>
							<td>Relevant Rows</td>
							<td>74.11</td>
							<td>65.85</td>
						</tr>
						<tr>
							<td>Human</td>
							<td>84.8</td>
							<td>85.8</td>
						</tr>
					</tbody>
					<caption>Performance (accuracy %) of the InfoTabS RoBERTa<sub>Large</sub> model on original and counterfactual annotated data.</caption>
				</table>
			</center></div>
<p>So, TabPert has both, helped in the creation of an <b>effective</b> adversarial dataset, and helped <b>identify model weaknesses</b>!</p>
      

      
      <h2><a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>People</h2>
			<p style="text-align: justify;"> TabPert has been prepared by the following people at <a href="https://iitk.ac.in/">IIT Kanpur</a> and <a href="https://www.cs.utah.edu/"> School of Computing</a> of <a href="https://www.cs.utah.edu/">University of Utah</a>:</p>
			<figure>
				<img src="figures/nupur.jpg" style="width:25%;">
				<img src="figures/vivekg.jpg" style="width:25%;">
				<img src="figures/anshul.jpeg" style="width:21%;">
				<img src="figures/gaurav.jpg" style="width:25%;">
				<figcaption>From left to right, <a href="https://www.linkedin.com/in/nupur-jain-060b85189/">Nupur Jain</a>, <a href="https://vgupta123.github.io">Vivek Gupta</a>,  <a href="https://www.linkedin.com/in/anshul-rai-84152a159/">Anshul Rai</a> and <a href="http://www.linkedin.com/in/gaurav-kumar-1450971a8">Gaurav Kumar</a>. </figcaption>
			</figure>

      <h2>
        <a
          id="user-content-header-2"
          class="anchor"
          href="#header-2"
          aria-hidden="true"
          ><span class="octicon octicon-link"></span></a
        >Citation
      </h2>
      <p style="text-align: justify">
        Please cite our paper as below if you use TabPert.
      </p>
      <pre><code>@inproceedings{jain-etal-2021-tabpert,
    title = "{T}ab{P}ert : An Effective Platform for Tabular Perturbation",
    author = "Jain, Nupur  and
      Gupta, Vivek  and
      Rai, Anshul  and
      Kumar, Gaurav",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-demo.39",
    pages = "350--360",
    abstract = "To grasp the true reasoning ability, the Natural Language Inference model should be evaluated on counterfactual data. TabPert facilitates this by generation of such counterfactual data for assessing model tabular reasoning issues. TabPert allows the user to update a table, change the hypothesis, change the labels, and highlight rows that are important for hypothesis classification. TabPert also details the technique used to automatically produce the table, as well as the strategies employed to generate the challenging hypothesis. These counterfactual tables and hypotheses, as well as the metadata, is then used to explore the existing model{'}s shortcomings methodically and quantitatively.",
}</code></pre>
      <h2>
        <a
          id="user-content-header-2"
          class="anchor"
          href="#header-2"
          aria-hidden="true"
          ><span class="octicon octicon-link"></span></a
        >Acknowledgement
      </h2>
      <p style="text-align: justify">
        Authors appreciate the
        <a href="https://svivek.com/">Utah NLP group</a> members' valuable
        suggestions at various phases of the project, as well as the reviewers'
        helpful remarks. We also acknowledge NSF grants #1801446 (SATC) and
        #1822877 (Cyberlearning), as well as a kind donation from Verisk Inc. We
        also like to thank
        <a href="https://svivek.com/">Alokit Innovations</a> for providing a
        mentoring platform.
      </p>
    </section>
    <section id="Instructions"class="main-content tab">
    <h1>Annotation Instructions</h1>

      <p>
        These are the instructions for using TabPert. You should watch the
        <a href="https://www.youtube.com/watch?v=sbCH_zD53Kg">demonstration video</a> to see the platform in action.
      </p>

      <p>
        When you launch TabPert in your browser and open a particular Table for
        which you wish to generate counterfactual data, you will be presented
        with 3 tables (Table A, Table B, Table C) whose entries are created by
        shuffling data from similar tables during the automatic stage.
      </p>

      <p><img src="figures/Image_0.png" /></p>

      <p>
        These automatically perturbed tables can be edited by the user manually
        according to his needs. There are two major ways to do so
      </p>

      <p>
        <strong>Changing the Table</strong>: In this, we change the table in the
        several ways, as described below:
      </p>

      <ul>
        <li>
          <i>Drag and drop</i>: We can drag and drop key-value pairs within the
          table and also from one table to another.
        </li>
      </ul>
      <p><img src="figures/drag_original.gif" /></p>

      <li>
        <i>Changing the value in a particular entry</i>: We can just place our
        cursor and edit the values in a particular entry
      </li>
      <p><img src="figures/edit_row.gif" /></p>

      <li>
        <i>Changing the Key</i>: In this, we press the small pencil button next
        to the Key we wish to change and enter the key’s new value in the popup
      </li>
      <img src="figures/Image_5.png" /></p>
      <p><img src="figures/edit_section.gif" /></p>

      <li>
        Adding new entry or deleting existing entry: This can be done by using
        drag and drop along with the “add” and “delete” areas on the top of the
        tables
      </li>
      <p><img src="figures/Image_6.png" /></p>
      <p><img src="figures/add_row.gif" /></p>
      <p><img src="figures/delete_row.gif" /></p>
      
      <li>
        Adding a new section: Click the 'Add section' button below a table to do this.
      </li>
      <p><img src="figures/add_section.gif" /></p>

      <li>
        Deleting a section: Press the pencil icon beside the key and click 'Delete'.
      </li>
      <p><img src="figures/delete_section.gif" /></p>

      <p>
        <strong>Changing the hypothesis</strong>: We can also make changes in
        the hypothesis and capture the strategies used to make these changes in
        TabPert. The various ways are as follows:
      </p>

      <ul>
        <li>
          <i>Editing the text of Hypothesis:</i> This is done similar to editing
          the value in the table, i.e. just place your cursor on the hypothesis
          you wish to edit and change it to the desired value.
        </li>
      </ul>
      <p><img src="figures/Image_7.png" /></p>

      <ul>
        <li>
          <i>Editing the Label of Hypothesis:</i> The user can use the drop-down
          menu to select the label for the hypothesis out of (“C” for
          Contradictory; “E” for Entailed and “N” for neutral)
        </li>
      </ul>

      <li>
        <i>Adding the Table Changing strategy:</i> This is done by pressing the
        “+” button next to the hypothesis which opens the following pop-up. The
        user can select the relevant rows used to arrive at the correct label
        for the hypothesis and also select the strategy the user used to change
        the hypothesis label.
      </li>
      <p><img src="figures/Image_8.png" /></p>
      <p><img src="figures/hypotheses.gif" /></p>
    </section>
    <section class="main-content">
      <footer class="site-footer">
        <span class="site-footer-credits"
          >This page was generated by
          <a href="https://pages.github.com">GitHub Pages</a> using the
          <a href="https://github.com/jasonlong/cayman-theme">Cayman</a> theme
          by <a href="https://github.com/jasonlong">jasonlong</a>.</span
        >
      </footer>
</section>
  <script>
	function switchTab(evt, tab) {
  	var i, tabcontent, tablinks;
	  tabcontent = document.getElementsByClassName("tab");
	  for (i = 0; i < tabcontent.length; i++) {
	    tabcontent[i].style.display = "none";
	  }
	  tablinks = document.getElementsByClassName("tablinks");
	  for (i = 0; i < tablinks.length; i++) {
	    tablinks[i].className = tablinks[i].className.replace(" active", "");
	  }
	  document.getElementById(tab).style.display = "block";
	  console.log(tab);
	  console.log(document.getElementById(tab));
	  evt.currentTarget.className += " active";
}
</script>
  </body>
</html>
